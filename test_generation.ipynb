{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "from datasets import load_dataset\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f189148",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.5-flash\"\n",
    "OUT_DIR = pathlib.Path(\"generated_tests\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae0b1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docstring(prompt_text: str) -> str:\n",
    "    \"\"\"\n",
    "    HumanEval's `prompt` contains signature + triple-quoted docstring + `pass`.\n",
    "    We return the first triple-quoted block's contents.\n",
    "    \"\"\"\n",
    "    m = re.search(r'(\"\"\"|\\'\\'\\')(.*?)(\\1)', prompt_text, flags=re.DOTALL)\n",
    "    return (m.group(2).strip() if m else prompt_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6184636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HumanEval with 164 problems.\n"
     ]
    }
   ],
   "source": [
    "api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"Please set GOOGLE_API_KEY in your environment.\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "ds = load_dataset(\"openai/openai_humaneval\")[\"test\"]  # 164 items\n",
    "print(f\"Loaded HumanEval with {len(ds)} problems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2d6520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Complete\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(ds):\n",
    "    doc = extract_docstring(item[\"prompt\"])\n",
    "    prompt = f'\"\"\"\\n{doc}\\n\"\"\"\\nPlease generate 10 test cases in Python\\'s standard unittest format for this problem. Please ONLY generate test cases, assume the function exist.'\n",
    "\n",
    "    try:\n",
    "        resp = model.generate_content(prompt)\n",
    "        text = (resp.text or \"\").strip()\n",
    "        # If fences sneak in, strip them.\n",
    "        text = re.sub(r\"^```(?:python)?\\s*\", \"\", text)\n",
    "        text = re.sub(r\"\\s*```$\", \"\", text)\n",
    "\n",
    "        out_path = OUT_DIR / f\"HumanEval_{idx}.py\"\n",
    "        out_path.write_text(text, encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Problem {idx} failed: {e}\")\n",
    "        \n",
    "print(\"Generation Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7401322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 164 canonical solutions...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pathlib\n",
    "import textwrap\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# === CONFIG ===\n",
    "OUT_DIR = pathlib.Path(\"canonical_solutions\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INCLUDE_IMPORTS = True  # set False to drop import lines and keep only `def ...:` + body\n",
    "\n",
    "def extract_signature_from_prompt(prompt: str, include_imports: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    From HumanEval `prompt`, remove the triple-quoted docstring and 'pass',\n",
    "    then return the remaining code (imports + def line).\n",
    "    \"\"\"\n",
    "    # remove first triple-quoted docstring block (\"\"\"...\"\"\" or '''...''')\n",
    "    code_wo_doc = re.sub(r'(\"\"\"|\\'\\'\\')(.*?)(\\1)', '', prompt, flags=re.DOTALL)\n",
    "    # remove any bare 'pass' lines\n",
    "    code_wo_doc = re.sub(r'^[ \\t]*pass[ \\t]*\\r?\\n?', '', code_wo_doc, flags=re.MULTILINE)\n",
    "    # normalize whitespace\n",
    "    lines = [ln.rstrip() for ln in code_wo_doc.strip().splitlines() if ln.strip()]\n",
    "\n",
    "    if not lines:\n",
    "        raise ValueError(\"No signature content found in prompt.\")\n",
    "\n",
    "    # Find the first def line\n",
    "    def_idx = next((i for i, ln in enumerate(lines) if ln.lstrip().startswith(\"def \")), None)\n",
    "    if def_idx is None:\n",
    "        # fallback: sometimes there's a blank before def; just join everything\n",
    "        joined = \"\\n\".join(lines) + (\"\\n\" if not lines[-1].endswith(\"\\n\") else \"\")\n",
    "        return joined\n",
    "\n",
    "    if include_imports:\n",
    "        kept = lines[:def_idx+1]  # imports (if any) + the def line\n",
    "    else:\n",
    "        kept = [lines[def_idx]]   # only the def line\n",
    "\n",
    "    sig = \"\\n\".join(kept)\n",
    "    if not sig.endswith(\"\\n\"):\n",
    "        sig += \"\\n\"\n",
    "    return sig\n",
    "\n",
    "def assemble_module(signature_code: str, body_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Indent the canonical_solution body under the def line.\n",
    "    Handles cases where body is already (or not) indented.\n",
    "    \"\"\"\n",
    "    body = textwrap.dedent(body_code.rstrip(\"\\n\")) + \"\\n\"\n",
    "    body_indented = textwrap.indent(body, \"    \")\n",
    "    return signature_code + body_indented\n",
    "\n",
    "def get_split(ds_any) -> Dataset:\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      - a DatasetDict with key 'test'\n",
    "      - a Dataset that is already the split\n",
    "    \"\"\"\n",
    "    if isinstance(ds_any, DatasetDict):\n",
    "        return ds_any[\"test\"]\n",
    "    if isinstance(ds_any, Dataset):\n",
    "        return ds_any\n",
    "    raise TypeError(\"Provide a Hugging Face Dataset or DatasetDict (with 'test').\")\n",
    "\n",
    "try:\n",
    "    split = get_split(ds)       # if your variable is named ds\n",
    "except NameError:\n",
    "    ds = load_dataset(\"openai/openai_humaneval\")[\"test\"]  # 164 items\n",
    "    split = get_split(ds) \n",
    "\n",
    "print(f\"Writing {len(split)} canonical solutions...\")\n",
    "\n",
    "for i, item in enumerate(split):\n",
    "    task_id = item.get(\"task_id\", f\"HumanEval/{i}\")\n",
    "    entry_point = item.get(\"entry_point\", f\"task_{i}\")\n",
    "    prompt = item[\"prompt\"]\n",
    "    body = item[\"canonical_solution\"]\n",
    "\n",
    "    # 1) signature\n",
    "    signature = extract_signature_from_prompt(prompt, include_imports=INCLUDE_IMPORTS)\n",
    "\n",
    "    # 2) final module\n",
    "    final_code = assemble_module(signature, body)\n",
    "\n",
    "    # 3) filename like 000_entrypoint.py\n",
    "    idx_str = str(i).zfill(3)\n",
    "    out_path = OUT_DIR / f\"{idx_str}_{entry_point}.py\"\n",
    "    out_path.write_text(final_code, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
